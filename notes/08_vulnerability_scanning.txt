Vulnerability Scanning
----------------------

- we have to use some kind of an automated software, which relies on a database of known
  vulnerabilities
- we also need a scoring system so that we can prioritize some vulnerabilities above others
- good starting point: NIST Technical Guide to Information Security Testing and Assessment
    - Special Publication 800-115
    - set of recommendations
        - review techniques
        - network discovery
        - different scanning techniques
        - vulnerability validation (penetration testing)
        - social engineering
        - security assessment
        - post-testing activities

- reasons
    - testing controls
        - e.g. we buy a security solution (firewall, intrusion detection system, 2 factor
          authentication system, ...)
        - you should test whether it performs like you expect them to
    - identifying weak points
    - determining current security posture: how secure are we?

- types of scanning
    - network (network vulnerability scanner)
        - connect to the network to be scanned
        - makes a list of active hosts and devices
        - identify the types of devices
        - list the actual services that are running by looking at the open ports
        - last step is vulnerability scanning phase
        - check the findings against a vulnerability database
        - generate a security assessment report
        - tool: greenbone security assistant
    - applications
        - overlaps sometimes with web application scanning, because a lot of the local
          applications are actually wrappers for web applications
        - looking for missing patches and updates
        - identifying weaknesses in the server code
    - web
        - any type of website expecting some kind of an input
        - user input should be thoroughly analyzed, validated and sanitized
        - SQL injection, cross-site scripting
    - active
        - actively sending packets to get some responses
        - more reliable but easier to detect
    - passive
        - easier to perform
        - relies on capturing network traffic without actively interacting with nodes
        - completely nonintrusive, cannot be detected
        - doesn't provide you with that much information
    - credentialed
        - directly interact with applications
        - leverage a valid user account -> login and gather information
        - a lot of valuable information can be gained
        - you need to preconfigure some credentials in the scanner software and tell the
          scanner to use this credential
    - non-credentialed
        - the vulnerability scanner simply connects over the network, attempts to generate
          some kind of a response without actually having valid user privileges
        - behaving just like an outside user











- vulnerability scan reports
    - includes:
        - asset: item that was scanned (host, server, mobile device, ...)
        - vulnerability: what was discovered, is there a patch, how can it be mitigated?
        - CVSS score: Common Vulnerability Scoring System score
            - metric for comparing and prioritizing vulnerabilities
            - based on several factors
                - how easy to exploit
                - what privileges are needed
                - exposure on case of successful exploit
            - used to prioritize -> where to focus the efforts first

- CVE example (Common Vulnerabilities and Exposures)
    - code: CVE-2021-1879
        - year when the vulnerability was discovered: 2021
        - ID: 1879 (simply incremented by one every time a new vulnerability is discovered)
    - base score: numerically calculated
        - scale from 0 to 10, e.g. 6.1 MEDIUM
                         0 : none
                0.1 -  3.9 : low
                4.0 -  6.9 : medium
                7.0 -  8.9 : high
                9.0 - 10.0 : critical
        - components:
            - base metrics
            - temporal metrics (optional)
                - make the vulnerability higher or lower depending on how much time has passed
                  since that vulnerability was discovered (maybe there is an update already)
            - environmental metrics (optional)
                - specific to your environment, how that certain software that has the
                  vulnerability is implemented in your environment (maybe a web server is
                  fully isolated)
    - vector: CVSS:3.1/AV:N/AC:L/PR:N/UI:R/S:C/C:L/I:L/A:N
    - base metrics:
        - AV : attack vector (network requirement for the attack to be successful)
            - N (Network) : can be performed over the network
            - A (Adjacent) : has to be performed in an adjacent network (e.g. must be launched
                             from the same shared physical or logical network, or from within
                             a secure or otherwise limited administrative domain)
            - L (Local) : not bound to the network stack, attacker must be able to access the
                          system locally (keyboard, console, SSH, relying on internal user
                          interaction)
            - P (Physical) : requires the attacker to physically touch or manipulate the
                             component
        - AC : attack complexity
            - L (Low) : does not require specialized access permissions
            - H (High) : a successful attack depends on conditions beyond the attacker's
                         control, attackers must be prepared, it takes a lot of work
            => low is bad...
        - PR : privileges required
            - N (None) : attacker can be unauthorized
            - L (Low) : basic user privileges are needed
            - H (High) : attacker needs significant privileges (e.g. administrative)
            => none is bad...
        - UI : user interaction
            - N (None) : no user interaction is required
            - R (Required) : a user must take some action (download files, insert a USB stick)
            => none is bad...
        - S  : scope (can the attack impact other components outside intended target)
            - U (Unchanged) : only affects resources managed by the same security authority
            - C (Changed) : other entities can be affected as well
            => changes is bad...
        - C, I, A  : confidentiality, integrity, availability
            - H (High) (e.g. high loss of availability = denial of service attack)
            - L (Low)
            - N (None)
            => high is bad...
        - exploitability metrics: AV, AC, PR, UI
        - impact metrics: C, I, A
    
    

    
    - temporal metrics
        - E (Exploit Code Maturity)
            => is there an exploit code already developed for this vulnerability?
            - X (Not defined)
            - H (High)
            - F (Functional)
            - P (Proof-of-Concept)
            - U (Unproven)
        - RL (Remediation Level)
            => is there a patch that can be used to update?
            - X (Not defined)
            - U (Unavailable)
            - W (Workaround)
            - T (Temporary fix)
            - O (Official fix)
        - RC (Report Confidence)
            => how much can we trust the existence of this vulnerability?
            - X (Not defined)
            - C (Confirmed)
            - R (Reasonable)
            - U (Unknown)
    - environmental metrics
        => enables us to tweak the CVSS score depending on the importance of the affected IT
           assets -> how important the loss of C/I/A is to us?
        - CR, IR, AR (Security Requirements) (confidentiality, integrity, availability)
            - X (Not defined)
            - H (High)
            - M (Medium)
            - L (Low)

- configuration vulnerabilities
    - review the configurations
    - e.g. you have a firewall installed, with all of the possible security mechanisms, but
           you don't enable them or is too permissive
    - 100% credentialed scan -> you need to access the configuration files
    - methods to automate this:
        - SCAP protocol (Security Content Automation Protocol)
            - standard for checking configurations against a predefined baseline
            - you need an ideal configuration to match against
            - how do you describe the baseline?
                - OVAL (Open Vulnerability and Assessment Language)
                    - XML
                    - describes your ideal configurations
                - XCCDF ( Extensible Configuration Checklist Description Format)
                    - XML
                    - describes best practices, kind of a checklist
        - compliance scan
            - specific for industries

- false results
    - false positive
        - not that bad
        - a vulnerability that was found is not really there or is not relevant
        - at most you are just wasting time
    - false negative
        - this is dangerous
        - there is a vulnerability in there that the scanner did not catch
        - no entry in the report
    - what can you do against false negatives?
        - multiple scanners, see if the results match
        - keep your signatures up-to-date
        - manually analyze some suspicious faults
        - see if there are suspicious traffic
        - make sure that the scanner is configured correctly
        - scanning process looks like the reconnaissance phase of an attack and might gets
          blocked -> scanning traffic must be allowed
        - use credentials in the scanner as well, gives much more information
        - is the baseline that you are comparing against up-to-date?
        - does the result apply to your network?
        - there might be some vulnerabilities that are not worth the effort (low score)